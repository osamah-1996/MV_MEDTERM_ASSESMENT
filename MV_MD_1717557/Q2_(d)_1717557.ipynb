{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "d) Replace your defined ConvNet in b) with a pre-trained model. Then, proceed with a transfer learning and finetune the model for the COVID-19 dataset. **(10 marks)**"
      ],
      "metadata": {
        "id": "H4w-9xnlGOpR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gu5EoMTZpGPe"
      },
      "outputs": [],
      "source": [
        "#import all the nessary libraries....\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yD2vu2-BpGP2"
      },
      "outputs": [],
      "source": [
        "#datset loader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import random\n",
        "from pandas.core.common import flatten\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YlBTvIC7pGP2"
      },
      "outputs": [],
      "source": [
        "# Applying Transforms to the Data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "image_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(size=(32,32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(size=(32,32)),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbPvryT3pGP3"
      },
      "source": [
        "Next, we create the Train, Valid, and Test sets. Here we create separate lists of image paths for Train, Valid, and Test sets. These will be used in our Dataset class which will be defined for a custom dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "dataset = '/content/gdrive/My Drive/covid'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSAxJ0sIlauo",
        "outputId": "48997c0f-4fe8-4db6-ac9f-e94856a847ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4QyD3_gspGP3",
        "outputId": "709b6780-284f-4abc-cb25-2c9da7f845cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_image_path example:  /content/gdrive/My Drive/covid/train/Covid/COVID-00003a.jpg\n",
            "class example:  Viral Pneumonia\n",
            "Train size: 251\n",
            "Test size: 66\n"
          ]
        }
      ],
      "source": [
        "####################################################\n",
        "#       Create Train, Valid and Test sets\n",
        "####################################################\n",
        "train_data_path = dataset + '/train' \n",
        "test_data_path = dataset + '/test'\n",
        "\n",
        "train_image_paths = [] #to store image paths in list\n",
        "classes = [] #to store class values\n",
        "\n",
        "#1.\n",
        "# get all the paths from train_data_path and append image paths and class to to respective lists\n",
        "\n",
        "for data_path in glob.glob(train_data_path + '/*'):\n",
        "    classes.append(data_path.split('/')[-1]) \n",
        "    train_image_paths.append(glob.glob(data_path + '/*'))\n",
        "    \n",
        "train_image_paths = list(flatten(train_image_paths))\n",
        "random.shuffle(train_image_paths)\n",
        "\n",
        "print('train_image_path example: ', train_image_paths[0])\n",
        "print('class example: ', classes[0])\n",
        "\n",
        "#2.\n",
        "# create the test_image_paths\n",
        "test_image_paths = []\n",
        "for data_path in glob.glob(test_data_path + '/*'):\n",
        "    test_image_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "test_image_paths = list(flatten(test_image_paths))\n",
        "\n",
        "print(\"Train size: {}\\nTest size: {}\".format(len(train_image_paths), len(test_image_paths)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WnFBuLIpGP5"
      },
      "source": [
        "We can’t use the class names directly for models. We create mappings of classes to index and index to classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2pWX-w_OpGP5",
        "outputId": "dc97e1a5-403d-4fba-d50f-40458b018ddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Viral Pneumonia': 0, 'Normal': 1, 'Covid': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#######################################################\n",
        "#      Create dictionary for class indexes\n",
        "#######################################################\n",
        "\n",
        "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
        "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YIA3jjz8pGP6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "#######################################################\n",
        "#               Define Dataset Class\n",
        "#######################################################\n",
        "\n",
        "class fruitDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=False):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filepath = self.image_paths[idx]\n",
        "#         image = cv2.imread(image_filepath)\n",
        "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.open(image_filepath).convert('RGB') # if using torchvision transforms\n",
        "        # print(image_filepath)\n",
        "        label = image_filepath.split('/')[-2]\n",
        "        # print(label)\n",
        "        label = class_to_idx[label]\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image) # if using torchvision transforms\n",
        "        \n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US85U4HbpGP7"
      },
      "source": [
        "As can be seen above, __getitem__ expects an index. This is handled automatically by the dataloader which for every image in the batch runs __getitem__. In the code for __getitem__, we load the image at index “idx”, extract the label from the file path and then run it through our defined transform. The function returns the Tensor of the image array and its corresponding label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KwzBKz3jpGP7"
      },
      "outputs": [],
      "source": [
        "#######################################################\n",
        "#                  Create Dataset\n",
        "#######################################################\n",
        "\n",
        "train_dataset = fruitDataset(train_image_paths,image_transforms['train'])\n",
        "test_dataset = fruitDataset(test_image_paths,image_transforms['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zbqYu16a-6WY",
        "outputId": "32a2fd43-05bc-4571-c7d4-ce39f9d64f32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=None)\n",
              "    ToTensor()\n",
              "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_dataset.transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfUCDyO1pGP7"
      },
      "source": [
        "After creating the train_dataset, we can access one example as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JqZzTGeRpGP8",
        "outputId": "4ac487de-0827-4f7a-b70c-6ad0023e9903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of tensor for 50th image in train dataset:  torch.Size([3, 32, 32])\n",
            "The label for 50th image in train dataset:  1\n"
          ]
        }
      ],
      "source": [
        "print('The shape of tensor for 50th image in train dataset: ',train_dataset[49][0].shape)\n",
        "print('The label for 50th image in train dataset: ',train_dataset[49][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qApD_A6TpGP9"
      },
      "source": [
        "The final step. DataLoader class is used to load data in batches for the model. This helps us processing data in mini-batches that can fit within our GPU’s RAM. First, we import the DataLoader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "10uAPyqbpGP9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1czDr28pGP9"
      },
      "source": [
        "Initiating the dataloader by sending in an object of the dataset and the batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "G_rTsHDupGP-",
        "outputId": "5ef869fc-7855-49c2-f4c1-a8ab7a557e97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "251\n",
            "66\n"
          ]
        }
      ],
      "source": [
        "#######################################################\n",
        "#                  Create Dataloader                     #\n",
        "#######################################################\n",
        "\n",
        "# Turn train and test custom Dataset's into DataLoader's\n",
        "from torch.utils.data import DataLoader\n",
        "trainloader = DataLoader(dataset=train_dataset, # use custom created train Dataset\n",
        "                                     batch_size=32, # how many samples per batch?\n",
        "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more)\n",
        "                                     shuffle=True) # shuffle the data?\n",
        "\n",
        "testloader = DataLoader(dataset=test_dataset, # use custom created test Dataset\n",
        "                                    batch_size=32, \n",
        "                                    num_workers=0, \n",
        "                                    shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_data_size = len(trainloader.dataset)\n",
        "test_data_size = len(testloader.dataset)\n",
        "\n",
        "print(train_data_size)\n",
        "print(test_data_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxnuI5HcpGP-"
      },
      "source": [
        "Once we have the dataloader instance — trainloader, we can use an iterator to access the data like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0_HtQrflpGP-",
        "outputId": "9ba01357-9a3d-4a79-a757-52eaed06ee5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#batch of image tensor\n",
        "next(iter(trainloader))[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wtNMfI8EpGP_",
        "outputId": "f1ec4dac-ed74-4555-a801-e9349d9e6eaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#batch of the corresponding labels\n",
        "next(iter(trainloader))[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBhTZjI7pGQA"
      },
      "source": [
        "This is what we use to batch out the data in our training loop. Every time we run the iterator, the dataloader selects the next 64 indexes and runs it through the __getitem__ in dataset class one by one and then returns it to the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mx0Es2OmpGQA",
        "outputId": "27fce83a-f6a6-4d8e-ab56-ffc8755e5979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f4bf49e681d14fb39052eceefbd68b70",
            "3fad1eae550b4a678ef948777cfc1124",
            "99e67f859b2c44b994d49d07679b574b",
            "f1816b998ab6412391b45ca49c2bc688",
            "21ac953cf5d040898a0b2bbc61d94682",
            "6348e6f3889e4f52977ba3279b920540",
            "e2e6237c405a4da6af8afcd8b714ee4e",
            "52e15fe78d6d4df4b86a03b9a53aa417",
            "3d0acaad3b444319bd9b6b350dcb65e9",
            "535fe15c5d2c46d69be8489d00bf26a9",
            "bfee2c7bd1064a269b5e6ea5975607cf"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4bf49e681d14fb39052eceefbd68b70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.fc = nn.Linear(num_ftrs, 3)\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "model.to(device)\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3A2QvpFn0lC",
        "outputId": "e49c0447-e0ae-4a67-bdb5-d13499c57db6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 3]           1,539\n",
            "================================================================\n",
            "Total params: 11,178,051\n",
            "Trainable params: 11,178,051\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 106.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Hj9UqJUapGQA"
      },
      "outputs": [],
      "source": [
        "import time # to calculate training time\n",
        "\n",
        "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "  \n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "    \n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "        \n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            \n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "            \n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "            \n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "            \n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "            \n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(testloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "            \n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size \n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_test_loss = valid_loss/test_data_size \n",
        "        avg_test_acc = valid_acc/test_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
        "                \n",
        "        epoch_end = time.time()\n",
        "    \n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
        "        \n",
        "        # Save if the model has best accuracy till now\n",
        "        torch.save(model, 'cifar10_model_'+str(epoch)+'.pt')\n",
        "            \n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1yQmzyDZpGQB",
        "outputId": "b855297b-ebb1-407d-f100-8567af94b116",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10\n",
            "Epoch : 000, Training: Loss: 1.0188, Accuracy: 51.3944%, \n",
            "\t\tValidation : Loss : 0.9618, Accuracy: 62.1212%, Time: 38.3076s\n",
            "Epoch: 2/10\n",
            "Epoch : 001, Training: Loss: 0.4784, Accuracy: 81.6733%, \n",
            "\t\tValidation : Loss : 0.8984, Accuracy: 68.1818%, Time: 14.2712s\n",
            "Epoch: 3/10\n",
            "Epoch : 002, Training: Loss: 0.2435, Accuracy: 93.6255%, \n",
            "\t\tValidation : Loss : 0.8539, Accuracy: 72.7273%, Time: 14.4563s\n",
            "Epoch: 4/10\n",
            "Epoch : 003, Training: Loss: 0.0882, Accuracy: 99.2032%, \n",
            "\t\tValidation : Loss : 0.6855, Accuracy: 77.2727%, Time: 14.6541s\n",
            "Epoch: 5/10\n",
            "Epoch : 004, Training: Loss: 0.0359, Accuracy: 100.0000%, \n",
            "\t\tValidation : Loss : 0.6852, Accuracy: 74.2424%, Time: 14.3204s\n",
            "Epoch: 6/10\n",
            "Epoch : 005, Training: Loss: 0.0213, Accuracy: 100.0000%, \n",
            "\t\tValidation : Loss : 0.7487, Accuracy: 72.7273%, Time: 14.3140s\n",
            "Epoch: 7/10\n",
            "Epoch : 006, Training: Loss: 0.0175, Accuracy: 100.0000%, \n",
            "\t\tValidation : Loss : 0.7901, Accuracy: 69.6970%, Time: 14.4421s\n",
            "Epoch: 8/10\n",
            "Epoch : 007, Training: Loss: 0.0208, Accuracy: 99.2032%, \n",
            "\t\tValidation : Loss : 0.8282, Accuracy: 72.7273%, Time: 14.6431s\n",
            "Epoch: 9/10\n",
            "Epoch : 008, Training: Loss: 0.0301, Accuracy: 99.2032%, \n",
            "\t\tValidation : Loss : 0.8089, Accuracy: 69.6970%, Time: 14.5582s\n",
            "Epoch: 10/10\n",
            "Epoch : 009, Training: Loss: 0.0135, Accuracy: 100.0000%, \n",
            "\t\tValidation : Loss : 0.8816, Accuracy: 71.2121%, Time: 14.6502s\n"
          ]
        }
      ],
      "source": [
        "# 4. Train the model for 10 epochs\n",
        " \n",
        "num_epochs = 10\n",
        "trained_model, history = train_and_validate(model, criterion, optimizer, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "90blSVXopGQC",
        "outputId": "4155402c-3655-4fb8-abc8-bf3afc7d0450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 5. Analyze the loss curve\n",
        "\n",
        "history = np.array(history)\n",
        "plt.plot(history[:,0:2])\n",
        "plt.legend(['Tr Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0,3)\n",
        "# plt.savefig('cifar10_loss_curve.png')\n",
        "plt.show()\n",
        "\n",
        "# 6. Analyze the accuracy curve\n",
        "\n",
        "plt.plot(history[:,2:4])\n",
        "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0,1)\n",
        "# plt.savefig('cifar10_accuracy_curve.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7 (pytorch_hasan)",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4bf49e681d14fb39052eceefbd68b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fad1eae550b4a678ef948777cfc1124",
              "IPY_MODEL_99e67f859b2c44b994d49d07679b574b",
              "IPY_MODEL_f1816b998ab6412391b45ca49c2bc688"
            ],
            "layout": "IPY_MODEL_21ac953cf5d040898a0b2bbc61d94682"
          }
        },
        "3fad1eae550b4a678ef948777cfc1124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6348e6f3889e4f52977ba3279b920540",
            "placeholder": "​",
            "style": "IPY_MODEL_e2e6237c405a4da6af8afcd8b714ee4e",
            "value": "100%"
          }
        },
        "99e67f859b2c44b994d49d07679b574b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e15fe78d6d4df4b86a03b9a53aa417",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d0acaad3b444319bd9b6b350dcb65e9",
            "value": 46830571
          }
        },
        "f1816b998ab6412391b45ca49c2bc688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_535fe15c5d2c46d69be8489d00bf26a9",
            "placeholder": "​",
            "style": "IPY_MODEL_bfee2c7bd1064a269b5e6ea5975607cf",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 121MB/s]"
          }
        },
        "21ac953cf5d040898a0b2bbc61d94682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6348e6f3889e4f52977ba3279b920540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e6237c405a4da6af8afcd8b714ee4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52e15fe78d6d4df4b86a03b9a53aa417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0acaad3b444319bd9b6b350dcb65e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "535fe15c5d2c46d69be8489d00bf26a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfee2c7bd1064a269b5e6ea5975607cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}